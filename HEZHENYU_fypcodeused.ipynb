{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT DEPENDENCIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym as gym\n",
    "from gym import spaces\n",
    "import pygame\n",
    "import numpy as np\n",
    "import random\n",
    "from gym.error import DependencyNotInstalled\n",
    "from typing import Optional, Union\n",
    "import math\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from stable_baselines3 import PPO , DQN , A2C\n",
    "from stable_baselines3.common.vec_env import VecFrameStack\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import datetime\n",
    "import torch as th\n",
    "\n",
    "\n",
    "log_dir = \"logs/Final/\" \n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Env Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTEP = 2000\n",
    "NUMBER_OF_SHIPS=4   #max 8 ship\n",
    "SCALAR =   2\n",
    "MAP = 200 # bigger map train longer\n",
    "Head_on_angle = 12.5\n",
    "violation = 1\n",
    "Arrival = 5\n",
    "Collision = 5\n",
    "TSP = 0.005\n",
    "#shipdomain size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# helper function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(x1,y1,x2,y2):\n",
    "    return math.sqrt(((x1-x2)**2) + ((y1-y2)**2))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def calc_tcpa_dcpa(x1, y1, x2, y2, speed1, speed2, heading1, heading2):\n",
    "    if distance(x1,y1,x2,y2) >= 10:\n",
    "        return 0,0\n",
    "    # convert headings to radians\n",
    "    theta1 = np.deg2rad(heading1)\n",
    "    theta2 = np.deg2rad(heading2)\n",
    "    \n",
    "    # calculate relative position and velocity vectors\n",
    "    rel_pos = np.array([x2 - x1, y2 - y1])\n",
    "    rel_vel = np.array([speed2 * np.cos(theta2), speed2 * np.sin(theta2)]) - np.array([speed1 * np.cos(theta1), speed1 * np.sin(theta1)])\n",
    "    \n",
    "    # calculate time to closest approach\n",
    "    tcpa = -np.dot(rel_pos, rel_vel) / np.dot(rel_vel, rel_vel)\n",
    "    if tcpa <= 0:\n",
    "        return 0,0\n",
    "           \n",
    "    # calculate distance at TCPA\n",
    "    dcpa = np.linalg.norm(rel_pos + tcpa * rel_vel)\n",
    "    \n",
    "    return tcpa, dcpa\n",
    "\n",
    "def Headon(x1,y1,b1,x2,y2,b2):\n",
    "    if distance(x1,y1,x2,y2) >= 10:\n",
    "        return False\n",
    "    else:\n",
    "        relative_bearing = b1 - b2\n",
    "        if relative_bearing <(180+Head_on_angle) and relative_bearing> (180-Head_on_angle):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "def give_way_crossing(x1,y1,b1,x2,y2,b2):\n",
    "    if distance(x1,y1,x2,y2) >= 10:\n",
    "        pass\n",
    "    else:\n",
    "        relative_bearing = b1 - b2\n",
    "        x_dist = x2-x1\n",
    "        y_dist = y2-y1\n",
    "        required = math.atan(y_dist/x_dist)*(180/np.pi)\n",
    "        if abs(relative_bearing) > 180:\n",
    "            return False\n",
    "        if abs(relative_bearing) < 25:\n",
    "            return False\n",
    "        if x_dist >=0 and y_dist >= 0 :\n",
    "            bearingr = required\n",
    "        elif x_dist>=0 and y_dist <= 0 :\n",
    "            bearingr = 90 + required\n",
    "        elif x_dist<=0 and y_dist <=0:\n",
    "            bearingr = 180 + required\n",
    "        elif x_dist<=0 and y_dist>=0:\n",
    "            bearingr = 360 - required\n",
    "        if b1 - bearingr < 0:\n",
    "            return True\n",
    "        if b1 - bearingr >0:\n",
    "            return False\n",
    "        \n",
    "        \n",
    "def overtake_giveway(x1,y1,b1,x2,y2,b2):\n",
    "    dist = distance(x1,y1,x2,y2)\n",
    "    if  dist>= 10:\n",
    "        return False\n",
    "    else:\n",
    "        relative_bearing = b1 - b2\n",
    "        x_dist = x2-x1\n",
    "        y_dist = y2-y1\n",
    "        required = math.atan(y_dist/x_dist)*(180/np.pi)\n",
    "        if relative_bearing >25 or relative_bearing < -25:\n",
    "            return False\n",
    "        if x_dist >=0 and y_dist >= 0 :\n",
    "            bearingr = required\n",
    "        elif x_dist>=0 and y_dist <= 0 :\n",
    "            bearingr = 90 - required\n",
    "        elif x_dist<=0 and y_dist <=0:\n",
    "            bearingr = 180 - required\n",
    "        elif x_dist<=0 and y_dist>=0:\n",
    "            bearingr = abs(required)\n",
    "        if abs(b1 - required >90):\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "        \n",
    "\n",
    "def average_nonzero(arr):\n",
    "    non_zero_values = arr[arr != 0]\n",
    "    avg = np.mean(non_zero_values)\n",
    "    return avg\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENVIROMENT BUILDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ssship(gym.Env):\n",
    "    metadata = {\n",
    "        \"render_modes\": [\"human\", \"rgb_array\"],\n",
    "        \"render_fps\": 50,\n",
    "    }\n",
    "    def __init__(self, render_mode: Optional[str] = None):\n",
    "        self.number_of_ships = NUMBER_OF_SHIPS\n",
    "        self.window_size = 512\n",
    "        self.action_space = spaces.Box(0,1,shape=(self.number_of_ships,),dtype=int)\n",
    "        self.agents = [[\"ship_\" + str(r) for r in range(self.number_of_ships)]]\n",
    "        self.observation_space =  spaces.Box(0,MAP/SCALAR , shape=(self.number_of_ships,9), dtype=int)\n",
    "        self.state =  np.zeros((self.number_of_ships,9))\n",
    "        self.screen_width = MAP/SCALAR\n",
    "        self.screen_height = self.screen_width\n",
    "        self.render_mode = render_mode\n",
    "        self.screen = None\n",
    "        self.clock = None\n",
    "        self.timestep = TIMESTEP\n",
    "        self.reward = 0\n",
    "        self.current = 0\n",
    "        self.arrived = 0\n",
    "        self.timetaken = 0\n",
    "        \n",
    "    def reset(self):\n",
    "        \n",
    "        self.state = np.zeros((self.number_of_ships,9))\n",
    "        self.current = 0\n",
    "        bad_random_destination = True\n",
    "        bad_random_spawn = True\n",
    "        for i in range(self.number_of_ships):\n",
    "            x = random.randint(0,self.screen_width)\n",
    "            y = random.randint(0,self.screen_width)\n",
    "            s = random.randint(5,15)/10\n",
    "            bearing = random.randint(0,360)\n",
    "            Lx = random.randint(0,self.screen_width)\n",
    "            Ly = random.randint(0,self.screen_width)\n",
    "            le = random.randint(4,5)\n",
    "            wi = random.randint(3,4)       \n",
    "            while bad_random_destination:\n",
    "                if distance(x,y,Lx,Ly) < 10:\n",
    "                    Lx = random.randint(0,self.screen_width)\n",
    "                    Ly = random.randint(0,self.screen_width)\n",
    "                else:\n",
    "                    bad_random_destination = False\n",
    "            while bad_random_spawn:   \n",
    "                if distance(self.state[i][0],self.state[i][1],self.state[i-1][0],self.state[i-1][1]) < 10 and i!=0:\n",
    "                    x = random.randint(0,self.screen_width)\n",
    "                    y = random.randint(0,self.screen_width)\n",
    "                else:\n",
    "                    bad_random_spawn = False\n",
    "                    \n",
    "                    \n",
    "                \n",
    "            Arrived = 0\n",
    "            self.state[i] = [x,y,s,bearing,Lx,Ly,Arrived,le,wi]\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self.render()\n",
    "            \n",
    "        self.timestep= TIMESTEP\n",
    "        self.reward=0\n",
    "        self.arrived=0\n",
    "        \n",
    "        \n",
    "        \n",
    "        return self.state\n",
    "\n",
    "    def step(self,action):\n",
    "\n",
    "        reward = 0\n",
    "        self.timestep -=1\n",
    "        reward -= TSP\n",
    "        self.reward -= TSP\n",
    "\n",
    "        \n",
    "        \n",
    "        for n in range(self.number_of_ships):\n",
    "            bearing = self.state[n][3]\n",
    "            \n",
    "            \n",
    "            ix = self.state[n][0]\n",
    "            iy = self.state[n][1]\n",
    "            x = self.state[n][0]\n",
    "            y = self.state[n][1]\n",
    "            if self.state[n][6] == 0 :\n",
    "\n",
    "                if action[n]==0:\n",
    "                    self.state[n][3] += 15\n",
    "                if action[n]==1:\n",
    "                    self.state[n][3] -= 15\n",
    "                if action[n]==2:\n",
    "                    self.state[n][2] += 0.1\n",
    "                if action[n]==3:\n",
    "                    self.state[n][2] -= 0.1\n",
    "                if action[n]==4:\n",
    "                    pass\n",
    "\n",
    "                s = self.state[n][2]\n",
    "                bearing = self.state[n][3]\n",
    "                if (x<=0 or x>=self.screen_width) and (y<=0 and y>=self.screen_width):\n",
    "                    pass\n",
    "\n",
    "                elif (x>=self.screen_width) and (0<y<self.screen_width):\n",
    "                    self.state[n][0] = self.screen_width -1\n",
    "                    self.state[n][1] += s*np.cos((np.pi*bearing)/180)\n",
    "                elif (x<=0) and (0<y<self.screen_width):\n",
    "                    self.state[n][0] = 1\n",
    "                    self.state[n][1] += s*np.cos((np.pi*bearing)/180)\n",
    "\n",
    "                elif (y<=0) and (0<x<self.screen_width):\n",
    "                    self.state[n][1] = 1\n",
    "                    self.state[n][0] += s*np.sin((np.pi*bearing)/180)\n",
    "                elif (y>=self.screen_width) and (0<x<self.screen_width):\n",
    "                    self.state[n][1] = self.screen_width - 1\n",
    "                    self.state[n][0] += s*np.sin((np.pi*bearing)/180)\n",
    "                else:\n",
    "                    self.state[n][0] += s*np.cos((np.pi*bearing)/180)\n",
    "                    self.state[n][1] += s*np.sin((np.pi*bearing)/180)           \n",
    "        \n",
    "\n",
    "        terminated = False\n",
    "        \n",
    "        n_arrived = 0\n",
    "        for i in range (self.number_of_ships):\n",
    "            x = self.state[i][0]\n",
    "            y = self.state[i][1]\n",
    "            Lx = self.state[i][4]\n",
    "            Ly = self.state[i][5]\n",
    "            Arrived = self.state[i][6]\n",
    "            \n",
    "            e_distance = distance(x,y,Lx,Ly)\n",
    "            pre_distance = distance(ix,iy,Lx,Ly)\n",
    "            if e_distance <= 10/SCALAR and Arrived==0:\n",
    "                reward += Arrival\n",
    "                self.reward += Arrival\n",
    "                self.state[i][6] = 1\n",
    "                self.arrived +=1\n",
    "            \n",
    "                       \n",
    "            if self.arrived == self.number_of_ships:\n",
    "                terminated = True\n",
    "                \n",
    "  \n",
    "\n",
    "        for i in range(self.number_of_ships):\n",
    "            for j in range(self.number_of_ships):\n",
    "                violate = False\n",
    "                if i == j:\n",
    "                    pass\n",
    "                else:\n",
    "                    x = self.state[i][0]\n",
    "                    y = self.state[i][1]\n",
    "                    x2 = self.state[j][0]\n",
    "                    y2 = self.state[j][1]\n",
    "                    b1 = self.state[i][3]\n",
    "                    b2=self.state[j][3]\n",
    "                    speed1= self.state[i][2]\n",
    "                    speed2 = self.state[j][2]\n",
    "                    distance_bw = distance(x,y,x2,y2)\n",
    "                    \n",
    "                    if self.state[j][6]==0 and self.state[i][6]==0:\n",
    "                        tcpa,dcpa = calc_tcpa_dcpa(x, y, x2, y2, speed1, speed2, b1, b2)\n",
    "                        reward -= 1 - math.exp(-(tcpa+dcpa))\n",
    "                    \n",
    "                    if distance_bw < 7.5/SCALAR and self.state[j][6]==0 and self.state[i][6]==0 :\n",
    "                        reward -= Collision\n",
    "                        self.reward-= Collision\n",
    "                        terminated = True\n",
    "                        \n",
    "\n",
    "                    if self.state[j][6]==0 and self.state[i][6]==0:\n",
    "                        gw = overtake_giveway(x,y,b1,x2,y2,b2)\n",
    "                        gwc = give_way_crossing(x,y,b1,x2,y2,b2)\n",
    "                        ho = Headon(x,y,b1,x2,y2,b2)\n",
    "\n",
    "                        if gw and action[n] == 4:\n",
    "                            violate == True\n",
    "\n",
    "                        if gw and action[n] == 2:\n",
    "                            violate == True\n",
    "    #is slowing down but dont change direction considered give way?                        \n",
    "                        if gwc and action[n] ==4:\n",
    "                            violate == True\n",
    "\n",
    "                        if gwc and action[n] ==2:\n",
    "                            violate == True\n",
    "\n",
    "                        if ho and action[n] == 1:\n",
    "                            violate == True\n",
    "                        if violate:\n",
    "                            reward -= violation\n",
    "        \n",
    "            \n",
    "        if self.timestep == 0:\n",
    "            \n",
    "            terminated = True\n",
    "        \n",
    "        if self.arrived == self.number_of_ships:\n",
    "            terminated = True\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "        if self.render_mode == \"human\":\n",
    "            self.render()\n",
    "\n",
    "        info = {}\n",
    "\n",
    "        return self.state , reward , terminated , info    \n",
    "\n",
    "    def render(self):\n",
    "        if self.render_mode is None:\n",
    "            gym.logger.warn(\n",
    "                \"You are calling render method without specifying any render mode. \"\n",
    "                \"You can specify the render_mode at initialization, \"\n",
    "                f'e.g. gym(\"{self.spec.id}\", render_mode=\"rgb_array\")'\n",
    "            )\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            import pygame\n",
    "            from pygame import gfxdraw\n",
    "        except ImportError:\n",
    "            raise DependencyNotInstalled(\n",
    "                \"pygame is not installed, run ``\"\n",
    "            )\n",
    "\n",
    "        if self.screen is None:\n",
    "            pygame.init()\n",
    "            if self.render_mode == \"human\":\n",
    "                pygame.display.init()\n",
    "                self.screen = pygame.display.set_mode(\n",
    "                    (self.screen_width* SCALAR, self.screen_height* SCALAR)\n",
    "                )\n",
    "            else:  # mode == \"rgb_array\":\n",
    "                self.screen = pygame.Surface((self.screen_width* SCALAR, self.screen_height* SCALAR))\n",
    "\n",
    "            if self.clock is None:\n",
    "                self.clock = pygame.time.Clock()\n",
    "\n",
    "        world_width = self.screen_width* SCALAR\n",
    "        scale = self.screen_width* SCALAR / world_width* SCALAR\n",
    "\n",
    "        self.surf = pygame.Surface((self.screen_width* SCALAR, self.screen_height* SCALAR))\n",
    "        self.surf.fill((255, 255, 255))\n",
    "        \n",
    "        # color rendering\n",
    "        black = (0,0,0)\n",
    "        blue = (0,0,255)\n",
    "        red = (255,0,0)\n",
    "        green = (0,255,0)\n",
    "        yellow = (127,255,0)\n",
    "        pink = (255,20,147)\n",
    "        gray=(128,128,128)\n",
    "        turquoise = (0,206,209)\n",
    "        colors = [black,blue,red,green,yellow,pink,gray,turquoise]\n",
    "        \n",
    "        \n",
    "        for i in range(self.number_of_ships):\n",
    "            x = self.state[i][0] * SCALAR\n",
    "            y = self.state[i][1] * SCALAR\n",
    "            width = 5 * SCALAR\n",
    "            length = 2.5 * SCALAR\n",
    "            bearing = self.state[i][3] \n",
    "            Lx = self.state[i][4] * SCALAR\n",
    "            Ly = self.state[i][5] * SCALAR\n",
    "            \n",
    "            l,r,t,b = -width/2, width / 2, length / 2, -length / 2\n",
    "            coords = [(l, b), (l, t), (r, t), (r, b)]\n",
    "            coords = [(l, b), (l, t), (r, t), (r, b)]\n",
    "            coords = [((c[0] )*np.cos(np.pi/180*bearing) - (c[1])*np.sin(np.pi/180*bearing) +x , (c[1])*np.cos(np.pi/180*bearing) + (c[0])*np.sin(np.pi/180*bearing)+y) for c in coords]\n",
    "            \n",
    "            gfxdraw.aapolygon(self.surf, coords, colors[i])\n",
    "            gfxdraw.filled_polygon(self.surf, coords, colors[i])\n",
    "            \n",
    "            gfxdraw.circle(self.surf,int(Lx),int(Ly),10,colors[i])\n",
    "\n",
    "        self.surf = pygame.transform.flip(self.surf, False, True)\n",
    "        self.screen.blit(self.surf, (0, 0))\n",
    "        my_font = pygame.font.SysFont('Comic Sans MS', 10)\n",
    "        text_surface1 = my_font.render(\"reward:\"+str((round(self.reward,2))), False, (0, 0, 0))\n",
    "        self.screen.blit(text_surface1, (10,40))\n",
    "        if self.render_mode == \"human\":\n",
    "            pygame.event.pump()\n",
    "            self.clock.tick(self.metadata[\"render_fps\"])\n",
    "            pygame.display.flip()\n",
    "\n",
    "        elif self.render_mode == \"rgb_array\":\n",
    "            return np.transpose(\n",
    "                np.array(pygame.surfarray.pixels3d(self.screen)), axes=(1, 0, 2)\n",
    "            )\n",
    "        \n",
    "    def close(self):\n",
    "        if self.screen is not None:\n",
    "            import pygame\n",
    "            \n",
    "            pygame.display.quit()\n",
    "            pygame.quit()\n",
    "\n",
    "            self.isopen = False\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENV TESTING ( RANDOM TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ssship()\n",
    "\n",
    "episodes = 10\n",
    "scorelist = np.zeros((1,episodes))\n",
    "\n",
    "for i in range (1):\n",
    "    for episode in range(1, episodes+1):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        score = 0 \n",
    "        collisions = 0\n",
    "\n",
    "        while not done:\n",
    "            #env.render()\n",
    "            action = env.action_space.sample()\n",
    "            n_state, reward, done, info = env.step(action)\n",
    "            score+=reward\n",
    "            \n",
    "            \n",
    "        scorelist[i][episode-1] = score\n",
    "        #print('Episode:{} Score:{} '.format(episode, score))\n",
    "    \n",
    "env.close()\n",
    "scorelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.average(scorelist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ssship()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Training PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_path = os.path.join('Training', 'PPO Saved Models', '1M_2S_C5_R10_ent0.05_PPO')\n",
    "\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1, tensorboard_log=log_dir,clip_range=0.2,batch_size=64,ent_coef=0.05)\n",
    "model.learn(total_timesteps=3_000_000,tb_log_name=\"3M_2S_C5_R10_PPO\")\n",
    "model.save(ppo_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training DQN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self, state_shape, action_shape, gamma=0.95, epsilon=1.0, epsilon_min=0.01, epsilon_decay=0.995, learning_rate=0.001, memory_size=100000):\n",
    "        self.state_shape = state_shape\n",
    "        self.action_shape = action_shape\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.learning_rate = learning_rate\n",
    "        self.memory = deque(maxlen=memory_size)\n",
    "        self.model = self._build_model()\n",
    "        self.target_model = self._build_model()\n",
    "        self.update_target_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "        model = tf.keras.models.Sequential([\n",
    "            Dense(64, input_dim=self.state_shape[1], activation='relu'),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dense(self.action_shape[1], activation='linear')\n",
    "        ])\n",
    "        model.compile(loss='mse', optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "    def update_target_model(self):\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "\n",
    "        \n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action.reshape(self.action_shape), reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return np.random.randint(low=0, high=2, size=self.action_shape)\n",
    "        act_values = self.model.predict(state)\n",
    "        return np.round(act_values[0]).astype(int)\n",
    "\n",
    "    def replay(self, batch_size=32):\n",
    "        if len(self.memory) < batch_size:\n",
    "            return\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        states, targets = [], []\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = self.model.predict(state)\n",
    "            if done:\n",
    "                target[0][np.argmax(action)] = reward\n",
    "            else:\n",
    "                t = self.target_model.predict(next_state)[0]\n",
    "                target[0][np.argmax(action)] = reward + self.gamma * np.amax(t)\n",
    "            states.append(state[0])\n",
    "            targets.append(target[0])\n",
    "        self.model.fit(np.array(states), np.array(targets), epochs=1, verbose=0)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "    def load_model(self, name):\n",
    "        self.model.load_weights(name)\n",
    "\n",
    "    def save_model(self, name):\n",
    "        self.model.save_weights(name)\n",
    "\n",
    "\n",
    "state_shape = env.observation_space.shape\n",
    "action_shape = env.action_space.shape\n",
    "number_of_ships = NUMBER_OF_SHIPS\n",
    "state_shape = (number_of_ships, 9)\n",
    "action_shape = (number_of_ships, 1)\n",
    "agent = DQNAgent(state_shape=state_shape, action_shape=action_shape)\n",
    "\n",
    "episodes = 100\n",
    "batch_size = 32\n",
    "for episode in range(episodes):\n",
    "    state = np.zeros((number_of_ships, 9))\n",
    "    done = False\n",
    "    score = 0\n",
    "    while not done:\n",
    "        action = agent.act(state)\n",
    "        action = np.round(action).astype(int)\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        next_state = np.reshape(next_state, state_shape)\n",
    "        reward = reward if not done else -10\n",
    "        agent.remember(next_state, action, reward, next_state, done)\n",
    "        state = next_state\n",
    "        score += reward\n",
    "        if done:\n",
    "            agent.update_target_model()\n",
    "            print(\"episode: {}/{}, score: {}\".format(episode, episodes, score))\n",
    "        agent.replay(batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A2C_path = os.path.join('Training', 'A2C Saved Models', '1M_2S_C5_R10_A2C')\n",
    "model = A2C(\"MlpPolicy\", env, verbose=1, tensorboard_log=log_dir)\n",
    "model.learn(total_timesteps=1_000_000,tb_log_name=\"1M_2S_C5_R10_A2C\")\n",
    "model.save(A2C_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load(ppo_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ssship(render_mode=\"human\")\n",
    "episodes = 5\n",
    "obs = env.reset()\n",
    "scorelist=[]\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    dones = False\n",
    "    score = 0 \n",
    "    \n",
    "    while not dones:\n",
    "        #env.render()\n",
    "        action, _states = model.predict(obs)\n",
    "        obs, rewards, dones, info = env.step(action)\n",
    "        \n",
    "        score+=rewards\n",
    "    scorelist.append(score)\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "print('average:' + str(np.average(scorelist)))\n",
    "env.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUATE WITH COLLISION COUNT, ARRIVAL COUNT , TIME , VIOLATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ssship(gym.Env):\n",
    "    metadata = {\n",
    "        \"render_modes\": [\"human\", \"rgb_array\"],\n",
    "        \"render_fps\": 50,\n",
    "    }\n",
    "    def __init__(self, render_mode: Optional[str] = None):\n",
    "        self.number_of_ships = NUMBER_OF_SHIPS\n",
    "        self.window_size = 512\n",
    "        self.action_space = spaces.Box(0,1,shape=(self.number_of_ships,),dtype=int)\n",
    "        self.agents = [[\"ship_\" + str(r) for r in range(self.number_of_ships)]]\n",
    "        self.observation_space =  spaces.Box(0,MAP/SCALAR , shape=(self.number_of_ships,9), dtype=int)\n",
    "        self.state =  np.zeros((self.number_of_ships,9))\n",
    "        self.screen_width = MAP/SCALAR\n",
    "        self.screen_height = self.screen_width\n",
    "        self.render_mode = render_mode\n",
    "        self.screen = None\n",
    "        self.clock = None\n",
    "        self.timestep = TIMESTEP\n",
    "        self.reward = 0\n",
    "        self.current = 0\n",
    "        self.arrived = 0\n",
    "        self.collided = 0\n",
    "        self.violate = 0\n",
    "        \n",
    "    def reset(self):\n",
    "        \n",
    "        self.state = np.zeros((self.number_of_ships,9))\n",
    "        self.current = 0\n",
    "        bad_random_destination = True\n",
    "        bad_random_spawn = True\n",
    "        for i in range(self.number_of_ships):\n",
    "            x = random.randint(0,self.screen_width)\n",
    "            y = random.randint(0,self.screen_width)\n",
    "            s = random.randint(5,15)/10\n",
    "            bearing = random.randint(0,360)\n",
    "            Lx = random.randint(0,self.screen_width)\n",
    "            Ly = random.randint(0,self.screen_width)\n",
    "            le = random.randint(4,5)\n",
    "            wi = random.randint(3,4)       \n",
    "            while bad_random_destination:\n",
    "                if distance(x,y,Lx,Ly) < 10:\n",
    "                    Lx = random.randint(0,self.screen_width)\n",
    "                    Ly = random.randint(0,self.screen_width)\n",
    "                else:\n",
    "                    bad_random_destination = False\n",
    "            while bad_random_spawn:   \n",
    "                if distance(self.state[i][0],self.state[i][1],self.state[i-1][0],self.state[i-1][1]) < 10 and i!=0:\n",
    "                    x = random.randint(0,self.screen_width)\n",
    "                    y = random.randint(0,self.screen_width)\n",
    "                else:\n",
    "                    bad_random_spawn = False\n",
    "                    \n",
    "                    \n",
    "                \n",
    "            Arrived = 0\n",
    "            self.state[i] = [x,y,s,bearing,Lx,Ly,Arrived,le,wi]\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self.render()\n",
    "            \n",
    "        self.timestep= TIMESTEP\n",
    "        self.reward=0\n",
    "        self.arrived=0\n",
    "        self.collided = 0\n",
    "        self.timetaken = 0\n",
    "        self.violate = 0\n",
    "        \n",
    "        return self.state\n",
    "\n",
    "    def step(self,action):\n",
    "\n",
    "        reward = 0\n",
    "        self.timestep -=1\n",
    "        reward -= TSP\n",
    "        self.reward -= TSP\n",
    "        self.arrived = 0\n",
    "        self.timetaken = 1\n",
    "        self.collided = 0\n",
    "        self.violate = 0\n",
    "\n",
    "        \n",
    "        \n",
    "        for n in range(self.number_of_ships):\n",
    "            bearing = self.state[n][3]\n",
    "            \n",
    "            \n",
    "            ix = self.state[n][0]\n",
    "            iy = self.state[n][1]\n",
    "            x = self.state[n][0]\n",
    "            y = self.state[n][1]\n",
    "            if self.state[n][6] == 0 :\n",
    "\n",
    "                if action[n]==0:\n",
    "                    self.state[n][3] += 15\n",
    "                if action[n]==1:\n",
    "                    self.state[n][3] -= 15\n",
    "                if action[n]==2:\n",
    "                    self.state[n][2] += 0.1\n",
    "                if action[n]==3:\n",
    "                    self.state[n][2] -= 0.1\n",
    "                if action[n]==4:\n",
    "                    pass\n",
    "\n",
    "                s = self.state[n][2]\n",
    "                bearing = self.state[n][3]\n",
    "                if (x<=0 or x>=self.screen_width) and (y<=0 and y>=self.screen_width):\n",
    "                    pass\n",
    "\n",
    "                elif (x>=self.screen_width) and (0<y<self.screen_width):\n",
    "                    self.state[n][0] = self.screen_width -1\n",
    "                    self.state[n][1] += s*np.cos((np.pi*bearing)/180)\n",
    "                elif (x<=0) and (0<y<self.screen_width):\n",
    "                    self.state[n][0] = 1\n",
    "                    self.state[n][1] += s*np.cos((np.pi*bearing)/180)\n",
    "\n",
    "                elif (y<=0) and (0<x<self.screen_width):\n",
    "                    self.state[n][1] = 1\n",
    "                    self.state[n][0] += s*np.sin((np.pi*bearing)/180)\n",
    "                elif (y>=self.screen_width) and (0<x<self.screen_width):\n",
    "                    self.state[n][1] = self.screen_width - 1\n",
    "                    self.state[n][0] += s*np.sin((np.pi*bearing)/180)\n",
    "                else:\n",
    "                    self.state[n][0] += s*np.cos((np.pi*bearing)/180)\n",
    "                    self.state[n][1] += s*np.sin((np.pi*bearing)/180)           \n",
    "        \n",
    "\n",
    "        terminated = False\n",
    "        \n",
    "        n_arrived = 0\n",
    "        for i in range (self.number_of_ships):\n",
    "            x = self.state[i][0]\n",
    "            y = self.state[i][1]\n",
    "            Lx = self.state[i][4]\n",
    "            Ly = self.state[i][5]\n",
    "            Arrived = self.state[i][6]\n",
    "            \n",
    "            e_distance = distance(x,y,Lx,Ly)\n",
    "            pre_distance = distance(ix,iy,Lx,Ly)\n",
    "            if e_distance <= 10/SCALAR and Arrived==0:\n",
    "                reward += Arrival\n",
    "                self.reward += Arrival\n",
    "                self.state[i][6] = 1\n",
    "                self.arrived +=1\n",
    "            \n",
    "                       \n",
    "            if self.arrived == self.number_of_ships:\n",
    "                terminated = True\n",
    "                   \n",
    "        for i in range(self.number_of_ships):\n",
    "            for j in range(self.number_of_ships):\n",
    "                violate = False\n",
    "                if i == j:\n",
    "                    pass\n",
    "                else:\n",
    "                    x = self.state[i][0]\n",
    "                    y = self.state[i][1]\n",
    "                    x2 = self.state[j][0]\n",
    "                    y2 = self.state[j][1]\n",
    "                    b1 = self.state[i][3]\n",
    "                    b2=self.state[j][3]\n",
    "                    speed1= self.state[i][2]\n",
    "                    speed2 = self.state[j][2]\n",
    "                    distance_bw = distance(x,y,x2,y2)\n",
    "                    \n",
    "                    if self.state[j][6]==0 and self.state[i][6]==0:\n",
    "                        tcpa,dcpa = calc_tcpa_dcpa(x, y, x2, y2, speed1, speed2, b1, b2)\n",
    "                        reward -= 1 - math.exp(-(tcpa+dcpa))\n",
    "                    \n",
    "                    if distance_bw < 7.5/SCALAR and self.state[j][6]==0 and self.state[i][6]==0 :\n",
    "                        reward -= Collision\n",
    "                        self.reward-= Collision\n",
    "                        terminated = True\n",
    "                        \n",
    "\n",
    "                    if self.state[j][6]==0 and self.state[i][6]==0:\n",
    "                        gw = overtake_giveway(x,y,b1,x2,y2,b2)\n",
    "                        gwc = give_way_crossing(x,y,b1,x2,y2,b2)\n",
    "                        ho = Headon(x,y,b1,x2,y2,b2)\n",
    "\n",
    "                        if gw and action[n] == 4:\n",
    "                            violate == True\n",
    "\n",
    "                        if gw and action[n] == 2:\n",
    "                            violate == True\n",
    "    #is slowing down but dont change direction considered give way?                        \n",
    "                        if gwc and action[n] ==4:\n",
    "                            violate == True\n",
    "\n",
    "                        if gwc and action[n] ==2:\n",
    "                            violate == True\n",
    "\n",
    "                        if ho and action[n] == 1:\n",
    "                            violate == True\n",
    "                        if violate:\n",
    "                            self.violate += 1\n",
    "                            reward -= violation\n",
    "\n",
    "            \n",
    "        if self.timestep == 0:\n",
    "            \n",
    "            terminated = True\n",
    "        TE = 0\n",
    "        \n",
    "        if self.arrived == self.number_of_ships:\n",
    "            TE = self.timetaken\n",
    "            terminated = True\n",
    "                   \n",
    "        if self.render_mode == \"human\":\n",
    "            self.render()\n",
    "\n",
    "        info = {}\n",
    "        \n",
    "        \n",
    "\n",
    "        return self.state , reward , terminated , info  , self.arrived , self.collided , TE , self.violate\n",
    "\n",
    "    def render(self):\n",
    "        if self.render_mode is None:\n",
    "            gym.logger.warn(\n",
    "                \"You are calling render method without specifying any render mode. \"\n",
    "                \"You can specify the render_mode at initialization, \"\n",
    "                f'e.g. gym(\"{self.spec.id}\", render_mode=\"rgb_array\")'\n",
    "            )\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            import pygame\n",
    "            from pygame import gfxdraw\n",
    "        except ImportError:\n",
    "            raise DependencyNotInstalled(\n",
    "                \"pygame is not installed, run ``\"\n",
    "            )\n",
    "\n",
    "        if self.screen is None:\n",
    "            pygame.init()\n",
    "            if self.render_mode == \"human\":\n",
    "                pygame.display.init()\n",
    "                self.screen = pygame.display.set_mode(\n",
    "                    (self.screen_width* SCALAR, self.screen_height* SCALAR)\n",
    "                )\n",
    "            else:  # mode == \"rgb_array\":\n",
    "                self.screen = pygame.Surface((self.screen_width* SCALAR, self.screen_height* SCALAR))\n",
    "\n",
    "            if self.clock is None:\n",
    "                self.clock = pygame.time.Clock()\n",
    "\n",
    "        world_width = self.screen_width* SCALAR\n",
    "        scale = self.screen_width* SCALAR / world_width* SCALAR\n",
    "\n",
    "        self.surf = pygame.Surface((self.screen_width* SCALAR, self.screen_height* SCALAR))\n",
    "        self.surf.fill((255, 255, 255))\n",
    "        \n",
    "        # color rendering\n",
    "        black = (0,0,0)\n",
    "        blue = (0,0,255)\n",
    "        red = (255,0,0)\n",
    "        green = (0,255,0)\n",
    "        yellow = (127,255,0)\n",
    "        pink = (255,20,147)\n",
    "        gray=(128,128,128)\n",
    "        turquoise = (0,206,209)\n",
    "        colors = [black,blue,red,green,yellow,pink,gray,turquoise]\n",
    "        \n",
    "        \n",
    "        for i in range(self.number_of_ships):\n",
    "            x = self.state[i][0] * SCALAR\n",
    "            y = self.state[i][1] * SCALAR\n",
    "            width = 5 * SCALAR\n",
    "            length = 2.5 * SCALAR\n",
    "            bearing = self.state[i][3] \n",
    "            Lx = self.state[i][4] * SCALAR\n",
    "            Ly = self.state[i][5] * SCALAR\n",
    "            \n",
    "            l,r,t,b = -width/2, width / 2, length / 2, -length / 2\n",
    "            coords = [(l, b), (l, t), (r, t), (r, b)]\n",
    "            coords = [(l, b), (l, t), (r, t), (r, b)]\n",
    "            coords = [((c[0] )*np.cos(np.pi/180*bearing) - (c[1])*np.sin(np.pi/180*bearing) +x , (c[1])*np.cos(np.pi/180*bearing) + (c[0])*np.sin(np.pi/180*bearing)+y) for c in coords]\n",
    "            \n",
    "            gfxdraw.aapolygon(self.surf, coords, colors[i])\n",
    "            gfxdraw.filled_polygon(self.surf, coords, colors[i])\n",
    "            \n",
    "            gfxdraw.circle(self.surf,int(Lx),int(Ly),10,colors[i])\n",
    "\n",
    "        self.surf = pygame.transform.flip(self.surf, False, True)\n",
    "        self.screen.blit(self.surf, (0, 0))\n",
    "        my_font = pygame.font.SysFont('Comic Sans MS', 10)\n",
    "        text_surface1 = my_font.render(\"reward:\"+str((round(self.reward,2))), False, (0, 0, 0))\n",
    "        self.screen.blit(text_surface1, (10,40))\n",
    "        if self.render_mode == \"human\":\n",
    "            pygame.event.pump()\n",
    "            self.clock.tick(self.metadata[\"render_fps\"])\n",
    "            pygame.display.flip()\n",
    "\n",
    "        elif self.render_mode == \"rgb_array\":\n",
    "            return np.transpose(\n",
    "                np.array(pygame.surfarray.pixels3d(self.screen)), axes=(1, 0, 2)\n",
    "            )\n",
    "        \n",
    "    def close(self):\n",
    "        if self.screen is not None:\n",
    "            import pygame\n",
    "            \n",
    "            pygame.display.quit()\n",
    "            pygame.quit()\n",
    "\n",
    "            self.isopen = False\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ssship()\n",
    "\n",
    "episodes = 20\n",
    "scorelist = np.zeros((1,episodes))\n",
    "arrlist = np.zeros((1,episodes))\n",
    "collist = np.zeros((1,episodes))\n",
    "timelist = np.zeros((1,episodes))\n",
    "violist = np.zeros((1,episodes))\n",
    "\n",
    "\n",
    "for i in range (1):\n",
    "    for episode in range(1, episodes+1):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        score = 0 \n",
    "        collisions = 0\n",
    "        arrived= 0\n",
    "        time = 0\n",
    "        viol=0\n",
    "        \n",
    "\n",
    "        while not done:\n",
    "            #env.render()\n",
    "            action, _states = model.predict(obs)\n",
    "            n_state, reward, done, info,arr,col,te,vio = env.step(action)\n",
    "            score+=reward\n",
    "            arrived += arr\n",
    "            collisions += col\n",
    "            time += te\n",
    "            viol += vio\n",
    "            \n",
    "            \n",
    "\n",
    "        scorelist[i][episode-1] = score\n",
    "        arrlist[i][episode-1] = arrived\n",
    "        collist[i][episode-1] = collisions\n",
    "        timelist[i][episode-1] = time\n",
    "        violist[i][episode-1] = viol\n",
    "        \n",
    "        #print('Episode:{} Score:{} '.format(episode, score))\n",
    "    \n",
    "env.close()\n",
    "scorelist\n",
    "print(np.average(scorelist))\n",
    "\n",
    "\n",
    "\n",
    "print('number of episodes with collision: ' + str(np.count_nonzero(collist == 1)))\n",
    "print('number of arrival,average per episode: ' + str(np.average(arrlist) ))\n",
    "print('average time taken: ' + str(average_nonzero(timelist)))\n",
    "print('average violation: ' + str(np.average(violist) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ssship()\n",
    "\n",
    "episodes = 20\n",
    "scorelist = np.zeros((1,episodes))\n",
    "arrlist = np.zeros((1,episodes))\n",
    "collist = np.zeros((1,episodes))\n",
    "timelist = np.zeros((1,episodes))\n",
    "violist = np.zeros((1,episodes))\n",
    "\n",
    "for i in range (1):\n",
    "    for episode in range(1, episodes+1):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        score = 0 \n",
    "        collisions = 0\n",
    "        arrived= 0\n",
    "        time = 0\n",
    "        \n",
    "        while not done:\n",
    "            #env.render()\n",
    "            action = env.action_space.sample()\n",
    "            n_state, reward, done, info,arr,col,te,vio = env.step(action)\n",
    "            score+=reward\n",
    "            arrived += arr\n",
    "            collisions += col\n",
    "            time += te\n",
    "            viol += vio\n",
    "            \n",
    "        scorelist[i][episode-1] = score\n",
    "        arrlist[i][episode-1] = arrived\n",
    "        collist[i][episode-1] = collisions\n",
    "        timelist[i][episode-1] = time\n",
    "        violist[i][episode-1] = viol\n",
    "        \n",
    "        #print('Episode:{} Score:{} '.format(episode, score))\n",
    "    \n",
    "env.close()\n",
    "scorelist\n",
    "print(np.average(scorelist))\n",
    "\n",
    "print(collist)\n",
    "print(timelist)\n",
    "\n",
    "print('number of episodes with collision: ' + str(np.count_nonzero(collist == 1)))\n",
    "print('number of arrival,average per episode: ' + str(np.average(arrlist) ))\n",
    "print('average time taken: ' + str(average_nonzero(timelist)))\n",
    "print('average violation: ' + str(np.average(violist) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%load_ext tensorboard\n",
    "import tensorflow as tf\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%tensorboard --logdir {log_dir}  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To-Do 17/2\n",
    "\n",
    "# can remove ship size if got time \n",
    "\n",
    "#reminder\n",
    "# DQN training, train seperately , unistall and install the older version of tensorflow and change action shape. \n",
    "# After training , change back if want to train ALG"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
